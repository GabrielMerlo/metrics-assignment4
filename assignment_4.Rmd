---
title: |
  | Assignment 4 
  | Econometrics I
subtitle: "Universidad Carlos III de Madrid"
author: "Gabriel Merlo"
date:
header-includes: 
  - \usepackage{float}
      \floatplacement{figure}{H}
output: pdf_document
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, fig.align = "center")
```

```{r include_packages, results = "hide"}
# install packages (if missing)
list_packages <- c("aod", "dplyr", "glmnet", "tidyr")
new_packages <- list_packages[!(list_packages %in% installed.packages()[,"Package"])]
if(length(new_packages)) install.packages(new_packages)

# Load packages
sapply(list_packages, require, character.only = TRUE)
```
` `

# Exercise 1

## (a) Read the data and estimate the ATE using the standard difference of sample means and a linear regression using as controls X.

` ` 

```{r part_1a, tidy = TRUE, tidy.opts = list(width.cutoff = 80)}
# Load data
penn <- as.data.frame(read.table("penn_jae.dat", header = TRUE))

# Keep control group, and treatment group 4
penn4 <- penn %>% filter(tg == 0 | tg == 4)

# Recode treatment variable
penn4$tg <- recode(penn4$tg, `4` = 1L) 

# Control variables
x <- c("female", "black", "othrace", "dep", "q2", "q3", "q4", "q5", "q6", "agelt35", "agegt54", "durable", "lusd", "husd")

# Log transformation of dependent variable
penn4$l_inuidur1 <- log(penn4$inuidur1)

# ATE from difference of sample means
diff_mean <- penn4 %>% 
  group_by(tg) %>% 
  summarize(mean = mean(l_inuidur1)) %>%
  spread(tg, mean) %>% 
  summarize(diff = `1` - `0`)
diff_mean

# ATE from linear regression with controls
ate <- lm(as.formula(paste("l_inuidur1 ~ tg +", paste(x, collapse = " + "))), data = penn4)
summary(ate)

# Checking balance of covariates
penn4 %>%
  group_by(tg) %>%
  select(x) %>%
  summarise_all(funs(mean(.)))
```

` `

The difference in the mean of log of duration of unemployment between treated and control groups is `r round(diff_mean, 3)`. This implies that those that receive the treatment spend less time being unemployed than those who don't get the treatment. 

Controlling by observable characteristics of the individuals, the log of duration of unemployment is `r round(abs(ate$coefficients[2]), 3)` smaller for the individuals that receive the treatment. Once we control by our vector of observables `x`, the effect of the treatment is `r round(abs(diff_mean) - abs(ate$coefficients[2]), 3)` smaller than when comparing using the difference of means (without controls). 

Ideally, randomization should balance the distribution of covariates among treated and untreated. One way to check if this is true is by calculating the sample mean difference in covariates between treatment and control groups. The balance is in general quite good but some characteristics are still not very well balanced (we could test if the differences are significant). This can explain the difference in the ATE by the two previous methods.

` `

## (b) One way to evaluate if the randomization is sucessful is to test the significance of $\theta_0$ in a Probit specification of the propensity score $p(x)=\Phi(x'\theta_0)$. Run such a test and interpret the results. Discuss the type of test, critical value, etc.

` `

```{r part1_b}
# Probit model estimation
penn4_ps <- glm(
  as.formula(paste("tg ~", paste(x, collapse = " + "))),
  family = binomial(link = "probit"), 
  data = penn4)
summary(penn4_ps)

# Extract coefficients
penn4_ps_coef <- coef(penn4_ps)

# Extract variance-covariance matrix
penn4_ps_sigma <- vcov(penn4_ps)

# Testing joint significance (Wald test)
penn4_ps_wt <- wald.test(Sigma = penn4_ps_sigma, b = penn4_ps_coef, Terms = 2:14)
penn4_ps_wt
```
To test if randomization was done correctly we can test the joint significance of the covariates on the probability of being treated. If the assignment of the treatment was truly random, no observable characteristic should be significant. To that end, we can apply a Wald test to the vector of coefficients $\theta_0$. 

The test result indicates that we can not reject the null of all coefficients being simultaneously equal to zero for a significance level of 0.05. So far, the evidence is not strong against the success of the randomization process. 

` `

## (c) Estimate the ATE by DML based on Lasso.

` ` 

```{r part1_c}
# Joel's Double Debiased Machine Learning function with lasso (DML)
b_DML <- function(Y,X,D){
  DML1 <- cv.glmnet(X, Y, alpha = 1)
  yhat <- predict(DML1, X)
  res1 <- Y - yhat
  DML2 <- cv.glmnet(X, D, alpha = 1)
  Dhat <- predict(DML2, X)
  res2 <- D - Dhat
  DML <- lm(res1 ~ 0 + res2)
  b_DML <- unname(coef(DML))
  return(b_DML)
}

# Calculating ATE using DML
ate_dml <- b_DML(penn4$l_inuidur1, as.matrix(penn4[, x]), penn4$tg)
ate_dml
```
` `

The ATE obtained using DML technique with lasso is `r round(ate_dml, 3)`.
